[
  {
    "timestamp": "2025-07-24T05:59:15.144092",
    "role": "user",
    "content": "B. Iris and the Tree\n\ntime limit per test3 seconds\n\nmemory limit per test256 megabytes\n\nGiven a rooted tree with the root at vertex 1\n\n. For any vertex i\n\n (1<i≤n\n\n) in the tree, there is an edge connecting vertices i\n\n and pi\n\n (1≤pi<i\n\n), with a weight equal to ti\n\n.\n\n\n\nIris does not know the values of ti\n\n, but she knows that ∑i=2nti=w\n\n and each of the ti\n\n is a non-negative integer.\n\n\n\nThe vertices of the tree are numbered in a special way: the numbers of the vertices in each subtree are consecutive integers. In other words, the vertices of the tree are numbered in the order of a depth-first search.\n\n\n\nThe tree in this picture satisfies the condition. For example, in the subtree of vertex 2\n\n, the vertex numbers are 2,3,4,5\n\n, which are consecutive integers.\n\nThe tree in this picture does not satisfy the condition, as in the subtree of vertex 2\n\n, the vertex numbers 2\n\n and 4\n\n are not consecutive integers.\n\nWe define dist(u,v)\n\n as the length of the simple path between vertices u\n\n and v\n\n in the tree.\n\n\n\nNext, there will be n−1\n\n events:\n\n\n\nIris is given integers x\n\n and y\n\n, indicating that tx=y\n\n.\n\nAfter each event, Iris wants to know the maximum possible value of dist(i,imodn+1)\n\n independently for each i\n\n (1≤i≤n\n\n). She only needs to know the sum of these n\n\n values. Please help Iris quickly get the answers.\n\n\n\nNote that when calculating the maximum possible values of dist(i,imodn+1)\n\n and dist(j,jmodn+1)\n\n for i≠j\n\n, the unknown edge weights may be different.\n\n\n\nInput\n\nEach test consists of multiple test cases. The first line contains a single integer t\n\n (1≤t≤104\n\n) — the number of test cases. The description of the test cases follows.\n\n\n\nThe first line of each test case contains two integers n\n\n and w\n\n (2≤n≤2⋅105\n\n, 0≤w≤1012\n\n) — the number of vertices in the tree and the sum of the edge weights.\n\n\n\nThe second line of each test case contains n−1\n\n integers p2,p3,…,pn\n\n (1≤pi<i\n\n) — the description of the edges of the tree.\n\n\n\nThen follow n−1\n\n lines indicating the events. Each line contains two integers x\n\n and y\n\n (2≤x≤n\n\n, 0≤y≤w\n\n), indicating that tx=y\n\n.\n\n\n\nIt is guaranteed that all x\n\n in the events are distinct. It is also guaranteed that the sum of all y\n\n equals w\n\n.\n\n\n\nIt is guaranteed that the sum of n\n\n over all test cases does not exceed 2⋅105\n\n.\n\n\n\nOutput\n\nFor each test case, output one line containing n−1\n\n integers, each representing the answer after each event.\n\n\n\nExample\n\nInputCopy\n\n4\n\n2 1000000000000\n\n1\n\n2 1000000000000\n\n4 9\n\n1 1 1\n\n2 2\n\n4 4\n\n3 3\n\n6 100\n\n1 2 3 2 1\n\n6 17\n\n3 32\n\n2 4\n\n4 26\n\n5 21\n\n10 511\n\n1 2 2 4 2 1 1 8 8\n\n3 2\n\n6 16\n\n10 256\n\n9 128\n\n2 1\n\n5 8\n\n8 64\n\n4 4\n\n7 32\n\nOutputCopy\n\n2000000000000\n\n25 18 18\n\n449 302 247 200 200\n\n4585 4473 2681 1567 1454 1322 1094 1022 1022\n\nNote\n\nIn the first test case, dist(1,2)=dist(2,1)=t2=w=1012\n\n, so dist(1,2)+dist(2,1)=2⋅1012\n\n.\n\n\n\nIn the second test case, the tree after Iris found out all tx\n\n is shown below:\n\n\n\n\n\ndist(1,2)=t2\n\n, dist(2,3)=t2+t3\n\n, dist(3,4)=t3+t4\n\n, dist(4,1)=t4\n\n. After the first event, she found out that t2=2\n\n, so dist(1,2)=2\n\n. At the same time:\n\n\n\ndist(2,3)\n\n is maximized if t3=7\n\n, t4=0\n\n. Then dist(2,3)=9\n\n.\n\ndist(3,4)\n\n and dist(4,1)\n\n are maximized if t3=0\n\n, t4=7\n\n. Then dist(3,4)=dist(4,1)=7\n\n.\n\nThus, the answer is 2+9+7+7=25\n\n.\n\n\n\nAfter the second event, she found out that t4=4\n\n, then t3=w−t2−t4=4\n\n. dist(1,2)=2\n\n, dist(2,3)=2+3=5\n\n, dist(3,4)=3+4=7\n\n, dist(4,1)=4\n\n. Thus, the answer is 2+5+7+4=18\n\n.\n\nUse Java."
  },
  {
    "timestamp": "2025-07-24T06:03:00.054920",
    "role": "assistant",
    "content": "**Analysis**\n\nWe have a rooted tree on \\(n\\) vertices (rooted at \\(1\\)), given in the special “DFS‐order” labeling: each node \\(i>1\\) has a parent \\(p_i<i\\), and the labels of each subtree form a contiguous interval \\([i,r_i]\\).  The edge \\((p_i,i)\\) has weight \\(t_i\\).  Initially all \\(t_i\\) are unknown nonnegative integers summing to\n\\[\n \\sum_{i=2}^n t_i = w.\n\\]\nWe then receive \\(n-1\\) events, each revealing a single edge‐weight \\(t_x=y\\).  After each reveal, for each \\(i=1,\\dots,n\\) we wish to know\n\\[\n\\max\\; \\mathrm{dist}(i,i\\!+\\!1\\pmod n)\n\\]\nsubject only to\n\n- the already‐revealed edges keep their known weights,\n- the remaining (unknown) edges are nonnegative integers summing to the remaining total \\(w-\\sum_{\\rm known}t_x\\),\n- we may re‐choose the unknown weights *independently for each pair* to maximize that single distance.\n\nFinally we output the *sum* of those \\(n\\) maxima for each event.\n\n---\n\n**Key observations**\n\n1.  The distance between two nodes \\(u,v\\) is the sum of edge‐weights along the unique path \\(P(u,v)\\).  For any path, the maximum possible sum is\n\\[\n\\bigl(\\sum_{\\substack{e\\in P\\cap \\text{(known edges)}}}t_e\\bigr)\n\\;+\\;\n\\bigl(\\sum_{\\substack{e\\in P\\cap \\text{(unknown edges)}}}t_e\\bigr)\n\\;\\le\\;\n\\bigl(\\sum_{\\substack{e\\in P\\cap \\text{(known)}}}t_e\\bigr)\n\\;+\\;\n\\bigl(\\sum_{\\substack{e\\text{ unknown}}}t_e\\bigr).\n\\]\nAnd we *can* achieve equality as long as \\(P\\) contains at least one unknown edge (we dump the entire remaining unknown‐sum onto one edge of \\(P\\)).\n\n2.  Let\n   - \\(S_{\\rm known}=\\sum\\) of all revealed \\(t_x\\),\n   - \\(R=w-S_{\\rm known}\\) = remaining total of the unknown edges,\n   - For each consecutive pair \\((i,i+1)\\) (with \\(n+1\\equiv 1\\)), let\n     \\[\n       F_i=\\sum_{e\\in P(i,i+1)\\cap\\mathrm{known}} t_e,\n     \\]\n     and let \\(\\mathbf{1}_i\\) be the indicator that \\(P(i,i+1)\\) has *at least* one unknown edge.\n\n   Then\n   \\[\n     \\max\\mathrm{dist}(i,i+1)\n     \\;=\\;F_i \\;+\\;\\mathbf{1}_i\\,R.\n   \\]\n   Summing over \\(i=1\\ldots n\\) gives\n   \\[\n     \\sum_{i=1}^n \\Bigl(F_i + \\mathbf{1}_i\\,R\\Bigr)\n     = \\Bigl(\\sum_{i=1}^n F_i\\Bigr)\\;+\\;R\\cdot\\Bigl(\\sum_{i=1}^n \\mathbf{1}_i\\Bigr).\n   \\]\n\n3.  One checks (by a small “DFS‐order adjacency argument”) that *each edge* \\((p_x,x)\\) appears in exactly *two* of the paths \\(P(i,i+1)\\).  Hence\n   \\[\n     \\sum_{i=1}^n F_i\n     =\\sum_{x\\text{ known}}2\\,t_x\n     = 2\\,S_{\\rm known}.\n   \\]\n   Also\n   \\[\n     \\sum_{i=1}^n \\mathbf{1}_i\n     = n \\;-\\;(\\text{# of pairs whose path is *entirely* known}).\n   \\]\n   We maintain a counter \\(\\mathrm{cnt}\\) of how many of the \\(n\\) pairs are already fully known.  Then\n   \\[\n     \\sum_{i=1}^n \\mathbf{1}_i\n     =n-\\mathrm{cnt},\n   \\]\n   and the total answer after revealing some edges is\n   \\[\n     2S_{\\rm known}\\;+\\;(w - S_{\\rm known})\\,(n-\\mathrm{cnt}).\n   \\]\n\n4.  **Dynamic maintenance of \\(\\mathrm{cnt}\\).**  Each time we reveal edge \\(x\\), exactly two of the \\(n\\) pairs \\((i,i+1)\\) *use* edge \\(x\\).  Concretely these two are\n   \\[\n     (x-1,x)\\quad\\text{and}\\quad (\\,r_x,\\;r_x+1\\!\\bmod n\\,),\n   \\]\n   where \\(r_x\\) is the right‐end of \\(x\\)’s subtree (\\(r_x=x+\\mathrm{subtree\\_size}[x]-1\\)).  A pair \\((i,i+1)\\) becomes *fully known* exactly when its path’s *last* unknown edge is just revealed.  Equivalently, just *before* we mark \\(x\\) known, that path had exactly one unknown edge (namely \\(x\\)).  \n\n   Hence for these two pairs we do a quick test:\n\n   – Let \\(\\mathrm{sumUnknown}(u,v)\\) = how many unknown edges remain on \\(P(u,v)\\).  \n   – If \\(\\mathrm{sumUnknown}(u,v)=1\\), *that* unknown must be \\(x\\), so this pair now becomes fully known, increment \\(\\mathrm{cnt}\\).\n\n5.  **Data‐structure for \\(\\mathrm{sumUnknown}(u,v)\\).**  We store each edge‐state (“unknown”=1, “known”=0) in a Fenwick tree (BIT) over a Heavy‐Light decomposition of the tree.  An edge \\((p_x,x)\\) is stored at the position of node \\(x\\).  Querying the sum of those bits on the path \\(u\\to v\\) is then a standard HLD‐path‐sum.\n\nEach event does two HLD path‐sum queries and one point‐update in the Fenwick tree, plus constant work.  Since we have \\(\\le2\\times10^5\\) total vertices/events, overall \\(O((n+\\!Q)\\,\\log^2n)\\) easily runs in a few seconds in Java.\n\n---\n\n**Implementation in Java**\n\n```java\nimport java.io.*;\nimport java.util.*;\n\npublic class Main {\n    static int N;\n    static long W;\n    static int[] parent, depth, sz, heavy, head, pos, rightEnd;\n    static List<Integer>[] children;\n    static Fenwick bit;\n    static int curt;\n    static long sumKnown;\n    static int fullyKnownCnt;\n\n    public static void main(String[] args) throws IOException {\n        BufferedReader br = new BufferedReader(new InputStreamReader(System.in));\n        StringTokenizer st;\n\n        int T = Integer.parseInt(br.readLine().trim());\n        StringBuilder out = new StringBuilder();\n\n        while (T-- > 0) {\n            st = new StringTokenizer(br.readLine());\n            N = Integer.parseInt(st.nextToken());\n            W = Long.parseLong(st.nextToken());\n\n            parent = new int[N+1];\n            depth  = new int[N+1];\n            sz      = new int[N+1];\n            heavy   = new int[N+1];\n            head    = new int[N+1];\n            pos     = new int[N+1];\n            rightEnd= new int[N+1];\n            children= new List[N+1];\n\n            for (int i = 1; i <= N; i++) {\n                children[i] = new ArrayList<>();\n                sz[i] = 1;\n            }\n\n            // read parents p[2..N]\n            st = new StringTokenizer(br.readLine());\n            for (int i = 2; i <= N; i++) {\n                int p = Integer.parseInt(st.nextToken());\n                parent[i] = p;\n                children[p].add(i);\n            }\n            parent[1] = 0;\n            depth[1] = 0;\n            // depths come easily since p[i] < i\n            for (int i = 2; i <= N; i++) {\n                depth[i] = depth[parent[i]] + 1;\n            }\n\n            // compute subtree sizes\n            for (int i = N; i >= 2; i--) {\n                sz[parent[i]] += sz[i];\n            }\n            // compute rightEnd = i + subtree_size[i] - 1\n            for (int i = 1; i <= N; i++) {\n                rightEnd[i] = i + sz[i] - 1;\n            }\n\n            // find heavy child\n            for (int u = 1; u <= N; u++) {\n                int maxSize = 0, hv = 0;\n                for (int v : children[u]) {\n                    if (sz[v] > maxSize) {\n                        maxSize = sz[v];\n                        hv = v;\n                    }\n                }\n                heavy[u] = hv;\n            }\n\n            // HLD: assign head[] and pos[]\n            curt = 0;\n            bit  = new Fenwick(N);\n            dfsDecompose();\n\n            // initially all edges unknown => BIT[x]=1 for x>1\n            for (int x = 2; x <= N; x++) {\n                bit.update(pos[x], 1);\n            }\n\n            sumKnown = 0L;\n            fullyKnownCnt = 0;\n\n            // process the n-1 events\n            int events = N - 1;\n            for (int e = 0; e < events; e++) {\n                st = new StringTokenizer(br.readLine());\n                int x = Integer.parseInt(st.nextToken());\n                long y = Long.parseLong(st.nextToken());\n\n                // the two pairs that use edge x:\n                //   (x-1,x)   and   (r_x, r_x+1 mod n)\n                int u1 = x - 1, v1 = x;\n                if (pathSum(u1, v1) == 1) {\n                    fullyKnownCnt++;\n                }\n                int r = rightEnd[x];\n                int u2 = r;\n                int v2 = (r == N ? 1 : r + 1);\n                if (pathSum(u2, v2) == 1) {\n                    fullyKnownCnt++;\n                }\n\n                // now mark edge x as known\n                bit.update(pos[x], -1);\n                sumKnown += y;\n\n                // compute answer\n                // 2*sumKnown + (W - sumKnown)*(N - fullyKnownCnt)\n                long rem = W - sumKnown;\n                long ans = 2L*sumKnown + rem*(N - fullyKnownCnt);\n                out.append(ans).append(' ');\n            }\n            out.append('\\n');\n        }\n\n        System.out.print(out);\n    }\n\n    // Heavy-Light Decomposition: assign head[u], pos[u] by a manual stack\n    static void dfsDecompose() {\n        Stack<Frame> st = new Stack<>();\n        st.push(new Frame(1, 1, 0, 0));\n\n        while (!st.isEmpty()) {\n            Frame f = st.pop();\n            int u = f.u;\n            if (f.state == 0) {\n                // first time at u\n                head[u] = f.h;\n                pos[u]  = ++curt;\n                // process heavy child first\n                if (heavy[u] != 0) {\n                    // after heavy, return to light‐child stage\n                    st.push(new Frame(u, f.h, 1, 0));\n                    st.push(new Frame(heavy[u], f.h, 0, 0));\n                } else {\n                    // no heavy, proceed to light\n                    st.push(new Frame(u, f.h, 1, 0));\n                }\n            } else {\n                // state==1 => do light children in order\n                int szc = children[u].size();\n                boolean pushed = false;\n                for (int i = f.nextChild; i < szc; i++) {\n                    int v = children[u].get(i);\n                    if (v == heavy[u]) continue;\n                    // resume at nextChild = i+1\n                    st.push(new Frame(u, f.h, 1, i+1));\n                    st.push(new Frame(v, v, 0, 0));\n                    pushed = true;\n                    break;\n                }\n                // if none left, we pop off f\n            }\n        }\n    }\n\n    // sum of the \"unknown\" bits on the path u->v\n    static int pathSum(int u, int v) {\n        int res = 0;\n        while (head[u] != head[v]) {\n            if (depth[head[u]] >= depth[head[v]]) {\n                res += bit.rangeSum(pos[head[u]], pos[u]);\n                u = parent[head[u]];\n            } else {\n                res += bit.rangeSum(pos[head[v]], pos[v]);\n                v = parent[head[v]];\n            }\n        }\n        // now on same chain\n        if (u != v) {\n            if (depth[u] > depth[v]) {\n                // sum from pos[v]+1 .. pos[u]\n                res += bit.rangeSum(pos[v]+1, pos[u]);\n            } else {\n                // sum from pos[u]+1 .. pos[v]\n                res += bit.rangeSum(pos[u]+1, pos[v]);\n            }\n        }\n        return res;\n    }\n\n    // Fenwick (BIT) for point‐update, prefix‐sum\n    static class Fenwick {\n        int n;\n        int[] f;\n        Fenwick(int n) { this.n = n; f = new int[n+1]; }\n        void update(int i, int d) {\n            for (; i <= n; i += i&-i) f[i] += d;\n        }\n        int query(int i) {\n            int s = 0;\n            for (; i > 0; i -= i&-i) s += f[i];\n            return s;\n        }\n        int rangeSum(int l, int r) {\n            if (l>r) return 0;\n            return query(r) - query(l-1);\n        }\n    }\n\n    // a little helper for the manual‐stack HLD\n    static class Frame {\n        int u, h, state, nextChild;\n        Frame(int _u, int _h, int _st, int _nc) {\n            u = _u; h = _h; state = _st; nextChild = _nc;\n        }\n    }\n}\n```\n\n**Explanation of the main parts**\n\n1. **Preprocessing**  \n   We read the parent array `p[2..n]`.  We build the children‐lists and compute\n   - `sz[u]` = size of subtree rooted at `u` (by accumulating children in reverse order  `n..2`),\n   - `rightEnd[u] = u + sz[u] - 1`, so the DFS‐interval of `u` is `[u,\\,rightEnd[u]]`.\n\n2. **Heavy‐Light Decomposition**  \n   We pick each node’s “heavy child” = the one child of maximum subtree‐size, then do a standard HLD to assign each node\n   - `head[u]` = the head of the current heavy‐path containing `u`,\n   - `pos[u]` = a global index from \\(1\\) to \\(n\\).  \n   We store the “unknown‐flag” of edge \\((p_u,u)\\) at position `pos[u]` in a Fenwick tree; node `1` has no parent‐edge so is always 0.\n\n3. **Fenwick Tree**  \n   We start with all edges unknown, so we initialize the Fenwick with 1’s at `pos[2..n]`.  An update to “reveal” edge `x` does `update(pos[x], -1)`.\n\n4. **Counting fully‐known pairs**  \n   Each edge `x` appears in exactly two of the consecutive‐label pairs:\n   - between vertex `x-1` and `x`,\n   - between `rightEnd[x]` and `(rightEnd[x] mod n)+1`.  \n   *Before* we mark `x` known, we query how many “unknown” edges remain on each of these two paths.  If exactly 1 is left, it *must* be `x`, so that pair now becomes fully known (increment `fullyKnownCnt`).\n\n5. **Answer formula**  \n   Let\n   - `sumKnown` = sum of all revealed \\(t_x\\),\n   - `rem = W - sumKnown`,\n   - `fullyKnownCnt` = how many of the \\(n\\) pairs have zero unknown edges,\n   - so `n - fullyKnownCnt` = how many pairs still have ≥1 unknown edge.\n   Then the total sum of maxima is\n   \\[\n     2\\cdot\\text{sumKnown}\n     \\;+\\;(W - \\text{sumKnown})\\;\\bigl(n - \\text{fullyKnownCnt}\\bigr).\n   \\]\n\nAll operations (Fenwick queries/updates and HLD path‐sums) run in \\(O(\\log n)\\) each, with two path‐sums per event, so overall \\(O((n+Q)\\log^2n)\\). This easily handles up to \\(2\\times10^5\\) total vertices/events in a few seconds."
  }
]