**Analysis**

We are given a string s of length n, and we must count the number of nonempty strings t≠“a” such that one can partition s into pieces each equal to t or to the single character “a,” using at least one copy of t.

Let’s mark all positions of s that hold a non‐'a' character.  Call their 0‐based indices p₀<p₁<…<pₖ₋₁, and let K=k be the number of those positions.  Observe:

1.  Any position holding a non‐'a' must lie inside one of our chosen occurrences of t — you cannot cover a non‐'a' with the single‐character piece “a.”  
2.  Gaps of uncovered positions (between our chosen occurrences of t) must consist only of 'a's so that they can be covered by single‐character “a” pieces.

We break all valid t into two disjoint types (which turn out to cover *all* possibilities):

**Case A (“many small t’s”).**  
We use one copy of t centered at each non‐'a' block, all disjoint.  More precisely, if we let 
```
M = min { p[i+1]−p[i]  :  i=0…K−2 },
```
then *any* length m≤M allows us to place a copy of t starting exactly at each p[i], and those intervals won’t overlap.  Of course for that to work the substrings  
```
s[p[0]…p[0]+m−1] , s[p[1]…p[1]+m−1], …, s[p[K−1]…p[K−1]+m−1]
```
must all coincide (so that they define a single candidate t).  Let
```
L = min_{1≤i<k}  LCP(p[0],p[i])
```
the minimum over pairwise LCP’s of the suffix at p[0] and the suffix at p[i].  Then exactly those m≤min(M, L) (and also ≤ the space remaining, namely n−p[K−1]) give valid “small‐t” in Case A.  That yields us
```
count_A = max( 0,  min(M, L, n−p[K−1])  ).
```

We do *not* apply Case A when K≤1, since it would double‐count the “single‐interval” situation; we will handle singletons in Case B below.

**Case B (“one big t”).**  
Here we cover *all* non‐'a's by a single copy of t.  That means t must contain the substring s[p[0]…p[K−1]] in one block.  Equivalently, t is any substring of s that *covers* the entire index‐interval [p[0],p[K−1]].  

It is a standard fact that in a suffix‐automaton one can count the number of distinct substrings that satisfy such an interval condition by storing, for each SAM‐state v

-  len[v] = maximal length of a substring in that class,
-  link[v] gives the “suffix‐link” (and so min‐ length+1 is len[ link[v] ]+1),
-  mx_end[v] = the maximum end‐position in the original string among *all* end‐positions of substrings in that class.

A substring u of length ℓ coming from state v can cover the interval [l…r] in s iff it has some occurrence ending at position e≥r and starts at e−ℓ+1≤l.  If we pick the *maximum* such e=mx_end[v]≥r, then the start‐condition becomes ℓ≥mx_end[v]−l+1, and also we need ℓ≥(r−l+1) so that it contains the whole block.  Since ℓ runs in the state‐interval

```
    linklen+1  ≤ ℓ  ≤  len[v],
```

we see that the allowed lengths in this state are

    lb = max(  len[link[v]]+1,
               D = (r−l+1),
               mx_end[v] − l + 1 )
    rb = len[v]

and we add max(0, rb−lb+1) to our total.

Putting Case A and Case B together (and handling the special “all‐a’s” case when K=0), we obtain an O(n log n) solution per string:

-  Build a *rolling‐hash* to compute the K−1 pairwise LCP’s between suffixes at p[0] and p[i] in O(log n) each.
-  Build a *suffix‐automaton* in O(n), propagate each state’s `mx_end`, and then sum up contributions.
-  Handle the trivial all‐a’s case by outputting n−1.

Overall over all test‐cases the total length is ≤3·10⁵ so this comfortably runs in time.

---

```java
import java.io.*;
import java.util.*;

public class Main {
    static final long HASH_BASE = 1315423911L;
    static final int MAXN = 300_000 + 5;
    // For rolling hash
    static long[] powBase = new long[MAXN];

    public static void main(String[] args) throws IOException {
        // Precompute powers of HASH_BASE
        powBase[0] = 1;
        for (int i = 1; i < MAXN; i++) {
            powBase[i] = powBase[i - 1] * HASH_BASE;
        }

        BufferedReader br = new BufferedReader(new InputStreamReader(System.in));
        int T = Integer.parseInt(br.readLine().trim());
        StringBuilder sb = new StringBuilder();
        while (T-- > 0) {
            String s = br.readLine().trim();
            int n = s.length();

            // 1) Collect positions of non-'a'
            ArrayList<Integer> p = new ArrayList<>();
            for (int i = 0; i < n; i++) {
                if (s.charAt(i) != 'a') {
                    p.add(i);
                }
            }
            int K = p.size();
            // If all 'a', answer = n-1
            if (K == 0) {
                sb.append(n - 1).append('\n');
                continue;
            }

            // Build rolling hash
            long[] h = new long[n];
            h[0] = (s.charAt(0) - 'a' + 1);
            for (int i = 1; i < n; i++) {
                h[i] = h[i - 1] * HASH_BASE + (s.charAt(i) - 'a' + 1);
            }
            // substring hash of s[l..r] inclusive
            // H(l,r) = h[r] - h[l-1]*powBase[r-l+1]
            class HashUtil {
                long get(int l, int r) {
                    long res = h[r];
                    if (l > 0) res -= h[l - 1] * powBase[r - l + 1];
                    return res;
                }
            }
            HashUtil HU = new HashUtil();

            // Case A: many small t's
            long caseA = 0;
            if (K >= 2) {
                // M = min gap between consecutive p's
                int M = n;
                for (int i = 1; i < K; i++) {
                    M = Math.min(M, p.get(i) - p.get(i - 1));
                }
                // Compute minimal LCP between suffix at p[0] and at p[i]
                int L = n;  // large
                for (int i = 1; i < K; i++) {
                    int x = p.get(0), y = p.get(i);
                    // binary search lcp
                    int low = 0, high = Math.min(n - x, n - y);
                    while (low < high) {
                        int mid = (low + high + 1) >>> 1;
                        if (HU.get(x, x + mid - 1) == HU.get(y, y + mid - 1)) {
                            low = mid;
                        } else {
                            high = mid - 1;
                        }
                    }
                    L = Math.min(L, low);
                }
                // also cannot exceed n - p[K-1]
                int maxLen2 = n - p.get(K - 1);
                int up = Math.min(Math.min(M, L), maxLen2);
                if (up > 0) caseA = up;
            }
            // Case B: one big t covering [l..r]
            int l = p.get(0), rpos = p.get(K - 1);
            int D = rpos - l + 1;

            // Build suffix‐automaton
            SuffixAutomaton sam = new SuffixAutomaton(n * 2);
            for (int i = 0; i < n; i++) {
                sam.extend(s.charAt(i) - 'a', i);
            }
            sam.propagateMaxPos();

            long caseB = 0;
            for (int v = 1; v < sam.size; v++) {
                if (sam.mxPos[v] >= rpos) {
                    int linkLen = sam.linkOf(v) >= 0 ? sam.lenOf(sam.linkOf(v)) : 0;
                    int lb = Math.max(Math.max(linkLen + 1, D),
                                      sam.mxPos[v] - l + 1);
                    int rb = sam.lenOf(v);
                    if (lb <= rb) {
                        caseB += (rb - lb + 1);
                    }
                }
            }

            sb.append(caseA + caseB).append('\n');
        }

        System.out.print(sb);
    }

    // --- Suffix Automaton with max‐endpos propagation ---
    static class SuffixAutomaton {
        static class State {
            int len, link;
            int[] next = new int[26];
            int maxPos;  // for propagating the maximum end‐position
            State() {
                len = 0; link = -1;
                Arrays.fill(next, -1);
                maxPos = -1;
            }
        }

        State[] st;
        int size, last;

        SuffixAutomaton(int maxStates) {
            st = new State[maxStates];
            for (int i = 0; i < maxStates; i++) st[i] = new State();
            st[0].len = 0; st[0].link = -1;
            size = 1; last = 0;
        }

        void extend(int c, int pos) {
            int cur = size++;
            st[cur].len = st[last].len + 1;
            st[cur].maxPos = pos;
            int p = last;
            for (; p != -1 && st[p].next[c] == -1; p = st[p].link) {
                st[p].next[c] = cur;
            }
            if (p == -1) {
                st[cur].link = 0;
            } else {
                int q = st[p].next[c];
                if (st[p].len + 1 == st[q].len) {
                    st[cur].link = q;
                } else {
                    int clone = size++;
                    st[clone].len = st[p].len + 1;
                    st[clone].link = st[q].link;
                    System.arraycopy(st[q].next, 0, st[clone].next, 0, 26);
                    st[clone].maxPos = st[q].maxPos;
                    for (; p != -1 && st[p].next[c] == q; p = st[p].link) {
                        st[p].next[c] = clone;
                    }
                    st[q].link = st[cur].link = clone;
                }
            }
            last = cur;
        }

        // After building, propagate each state's maxPos up the link‐tree
        void propagateMaxPos() {
            // Bucket states by length
            int maxLen = 0;
            for (int i = 0; i < size; i++) {
                maxLen = Math.max(maxLen, st[i].len);
            }
            int[] cnt = new int[maxLen + 1];
            for (int i = 0; i < size; i++) cnt[st[i].len]++;
            for (int i = 1; i <= maxLen; i++) cnt[i] += cnt[i - 1];
            int[] order = new int[size];
            for (int i = size - 1; i >= 0; i--) {
                order[--cnt[st[i].len]] = i;
            }
            // Propagate in decreasing order of len
            for (int i = size - 1; i > 0; i--) {
                int v = order[i];
                int p = st[v].link;
                if (p >= 0) {
                    st[p].maxPos = Math.max(st[p].maxPos, st[v].maxPos);
                }
            }
        }

        int lenOf(int v) { return st[v].len; }
        int linkOf(int v) { return st[v].link; }
        int getMaxPos(int v) { return st[v].maxPos; }
    }
}
```

**Explanation of the main steps**

1. **Scan non‐'a' positions**  
   We collect all indices `p[i]` where `s.charAt(p[i])!='a'`.  If there are none, the answer is simply `n−1` (all‐'a' string can be covered by a single block of length 2…n).

2. **Case A (“many small t’s”)**  
   - Compute  
     ```
       M = min_{i=0..K−2} ( p[i+1] − p[i] )
     ```  
     so that an interval of length m ≤ M placed at each `p[i]` will be disjoint.
   - Compute  
     ```
       L = min_{1≤i<K}  LCP( p[0], p[i] )
     ```  
     (using binary‐search+rolling‐hash) so that the substring of length m starting at each `p[i]` is the *same*.
   - Also we cannot exceed the end of the string: `m ≤ n−p[K−1]`.  
   - Thus  
     ```
       countA = max(0, min(M,L,n−p[K−1])).
     ```

3. **Case B (“one big t”)**  
   We want all distinct substrings of s that *cover* the interval `[p[0],p[K−1]]`.  
   It is a well‐known trick with a suffix‐automaton:  
   - Build the SAM, recording for each state v its `len[v]`, its `link[v]`, and maintain `mxPos[v]`, the maximum end‐position among all its end‐positions.
   - After building, do a pass in *decreasing* order of `len[v]` to propagate `mxPos` up the link tree:  
     ```
       mxPos[ link[v] ] = max( mxPos[ link[v] ], mxPos[v] ).
     ```
   - Now any substring of length ℓ in the equivalence‐class of v can cover `[l..r]` iff there is an occurrence ending at some `e = mxPos[v]≥r` and starting at `e−ℓ+1 ≤ l`.  This forces  
     ```
       ℓ ≥ e−l+1   and   ℓ ≥ (r−l+1).
     ```  
     Meanwhile ℓ runs in the interval `[linklen+1 .. len[v]]`.  Hence the count of admissible ℓ in state v is  
     ```
       rb = len[v],
       lb = max( linklen+1, r−l+1, mxPos[v]−l+1 ),
       add  max(0, rb−lb+1).
     ```
   Summing over all states gives the total number of distinct substrings that contain `[l..r]`.

Finally we output `countA + countB`.  This runs in  O(n log n) per test (thanks to the K×log n LCP work and O(n) suffix‐automaton).  Over all tests the total length is ≤3·10⁵, so we are well within the 2-second limit.